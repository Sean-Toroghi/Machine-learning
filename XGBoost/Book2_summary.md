# Book (2024): XGBoost for Regression Predictive Modeling and Time Series Analysis - summary and key takeaways


This summary is my takeaways and notes from reference book "XGBoost for Regression Predictive Modeling and Time Series Analysis" by Partha Pritam Deka and Joyce Weiner that was published in 2024.


---

__Evaluation metrics__

XGboost provides a range of evaluation [metrics](https://xgboost.readthedocs.io/en/stable/parameter.html#learning-task-parameters). The default metrics are: rmse for regression, and logloss for classification. Based on objective, the model picks the appropriate metric, if not specified. For example for "rank:map" the default metric is _mean average precision_.

While there are over 20 metrics, here is the list of ones that are used more frequently:
- rmse: root mean square error
- rmsle: root mean square log error: Default metric of reg:squaredlogerror objective. This metric reduces errors generated by outliers in dataset. But because log function is employed, rmsle might output nan when prediction value is less than -1.
- mae: mean absolute error
- mape: mean absolute percentage error
- mphe: mean Pseudo Huber error. Default metric of reg:pseudohubererror objective.
- logloss: negative log-likelihood
- error: Binary classification error rate. It is calculated as #(wrong cases)/#(all cases). For the predictions, the evaluation will regard the instances with prediction value larger than 0.5 as positive instances, and the others as negative instances.
- error@t: a different than 0.5 binary classification threshold value could be specified by providing a numerical value through ‘t’.
- merror: Multiclass classification error rate. It is calculated as #(wrong cases)/#(all cases).
- mlogloss: Multiclass logloss.
- auc: Receiver Operating Characteristic Area under the Curve. Available for classification and learning-to-rank tasks.
  - When used with binary classification, the objective should be binary:logistic or similar functions that work on probability.
  - When used with multi-class classification, objective should be multi:softprob instead of multi:softmax, as the latter doesn’t output probability. Also the AUC is calculated by 1-vs-rest with reference class weighted by class prevalence.
  - When used with LTR task, the AUC is computed by comparing pairs of documents to count correctly sorted pairs. This corresponds to pairwise learning to rank. The implementation has some issues with average AUC around groups and distributed workers not being well-defined.
  - On a single machine the AUC calculation is exact. In a distributed environment the AUC is a weighted average over the AUC of training rows on each node. therefore, distributed AUC is an approximation sensitive to the distribution of data across workers. Use another metric in distributed environments if precision and reproducibility are important.
  - When input dataset contains only negative or positive samples, the output is NaN. The behavior is implementation defined, for instance, scikit-learn returns instead.
- aucpr: Area under the PR curve. Available for classification and learning-to-rank tasks.
- pre: Precision at _k_. Supports only learning to rank task.
- ndcg: Normalized Discounted Cumulative Gain
- map: Mean Average Precision
- ndcg@n, map@n, pre@n: can be assigned as an integer to cut off the top positions in the lists for evaluation.
- ndcg-, map-, ndcg@n-, map@n-: In XGBoost, the NDCG and MAP evaluate the score of a list without any positive samples as 1. By appending “-” to the evaluation metric name, we can ask XGBoost to evaluate these scores as  to be consistent under some conditions.
- poisson-nloglik: negative log-likelihood for Poisson regression
- gamma-nloglik: negative log-likelihood for gamma regression
- cox-nloglik: negative partial log-likelihood for Cox proportional hazards regression
- gamma-deviance: residual deviance for gamma regression
- tweedie-nloglik: negative log-likelihood for Tweedie regression (at a specified value of the tweedie_variance_power parameter)
- aft-nloglik: Negative log likelihood of Accelerated Failure Time model. See Survival Analysis with Accelerated Failure Time for details.
- interval-regression-accuracy: Fraction of data points whose predicted labels fall in the interval-censored labels. Only applicable for interval-censored data (Survival Analysis with Accelerated Failure Time for details.)

---
